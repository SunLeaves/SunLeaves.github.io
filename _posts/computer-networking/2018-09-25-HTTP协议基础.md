---
layout:     post
title:      HTTP协议基础
subtitle:   
date:       2018-09-25
author:     xiezht
header-img: 
catalog: true
tags: 
    - 笔记
---

内容来源:

1. [HTTP协议入门-阮一峰](http://www.ruanyifeng.com/blog/2016/08/http.html)
2. [HTTP教程 \| 菜鸟教程](http://www.runoob.com/http/http-tutorial.html)
3. [HTTP协议 \| GitBook](https://hit-alibaba.github.io/interview/basic/network/HTTP.html)

## HTTP协议

一些基本概念：

* 基于TCP/IP通信协议来传递数据
* 工作于客户端/服务端架构
  + 使用URL(统一资源标识符)来传输数据和建立连接。（URL，统一资源标识符，用来描述一个网络上的资源）。
  + 客户端和服务端都是应用程序。如Web浏览器作为客户端发送HTTP请求，Apache Web服务器作为服务端发送响应数据。
* 三个特点：
  + 无连接，每次连接只处理一个请求，服务器对请求做出应答之后就断开连接
  + 媒体独立的。任何类型的数据都可以通过HTTP发送，客户端以及服务器指定使用适合MIME-Type内容类型
  + 无状态的。对事务的处理没有记忆能力。


### HTTP消息结构

分为两类：一类是请求消息，另一类是响应消息。

**客户端请求消息**：

* 请求行：
  + 请求方法
  + URL
  + 协议版本
* 请求头部
  + 头部字段名+值
* 空行
* 请求数据

**服务器响应信息**：

* 状态行
* 消息报头
* 空行
* 响应正文

### HTTP请求方法

**1.0及1.1版本**：

* GET：请求指定的页面信息，返回实体主体
  + GET可提交的数据量受到URL长度的限制，HTTP 协议规范没有对 URL 长度进行限制。这个限制是特定的浏览器及服务器对它的限制

* POST：向指定**资源**提交**数据**进行处理请求，数据包含在请求体内。并可能会导致新的资源的**创建**或者已有资源的**修改**
  + HTTP协议规范对POST提交的数据大小也没有限制。出于安全考虑，服务器软件在实现时会做一定的限制。
  + POST提交的数据包含在body部分。


* HEAD：类似GET，但只获取头部

* PUT：从客户端向服务器传送的数据**取代**指定的文档的内容
* DELETE：请求服务器删除指定的页面
* CONNECT：HTTP/1.1协议中预留给 能够将连接改为管道方式的代理服务器
* OPTIONS：允许客户端查看服务器的性能
* TRACE：回显服务器收到的请求，一般用于**测试/诊断**


### HTTP响应头信息

* Allow：服务器支持的请求方法

* Content-Encoding：响应内容的编码方式
  + 服务端应该根据请求信息的请求头部的Accent-Encoding来返回客户端接受的编码信息

* Content-Length：浏览器使用持久HTTP连接时需要该数据。

* Content-Type：文档的MIME类型。默认text/plain。
  + HttpServletResponse.setContenType

* Date：当前GMT时间。
  + HttpServletResponse.setDateHeader

* Expires：文档过期时间，过期则不再缓存

* Last-Modified：文档的最后改动时间。
  + if-Modified-Since：客户端请求头，对应请求视为一个条件GET

> **条件GET**
> 
> 减少不必要的带宽浪费。
> 
> 使用时机：客户端之前已经访问过某网站，并想再次访问。
> 
> 使用方式：客户端向服务器发送包查询上一次访问网站的时间后是否修改了页面，如果服务器没有更新（返回304 Not Modified响应），则客户端使用本地缓存即可。

* Location：表示客户应当到哪里提取文档。
  + HttpServletResponse.sendRedirect

* Refresh：表示浏览器应该在多长事件后刷新文档。（扩展，不属于HTTP1.1正式规范）

* Server：服务器名字

* Set-Cookie：设置和页面关联的Cookie
  + HttpServletResponse.addCookie

* WWW-Authenticate：客户应提供的授权信息。

* Keep-Alive：持久连接，使客户端到服务器的连接持续有效，避免后续请求连接的建立/重新建立。

> **持久连接**
> 
> HTTP1.1默认Connection: Keep-Alive。保持当前的TCP连接，存在一定的时长限制和请求次数限制。
> 
> Keep-Alive并没有改变HTTP的无状态特性，每个请求依然是独立的。同时它也不能保证客户端与服务器之间的连接一定是活跃的。唯一能保证的是当连接被关闭时能得到一个通知。因而不能让程序依赖于Keep-Alive的保持连接特性。
>
> 使用长连接，C/S通过两种方式判断本次传输是否结束：
> * 传输数据是否达到了Content-Length指示的大小。
> * 动态生成的文件没有Content-Length，是分块传输（chunked）的。需要根据chunked编码来判断。chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束。


* Transfer-Encoding：标识HTTP报文传输格式的头部值。
  + 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。
  + chunked块：块数据的字节数（十六进制标识）+ CRLF + 数据本身 + CRLF

> chunked
> 
> multipart 是一种 Content-Type，标示 HTTP 报文内容的类型，而 chunked 是一种传输格式，标示报头将以何种方式进行传输。
> 
> chunked传输无法预先知道数据长度，因此无法实现进度。
> 
> 服务器可以边生成内容边传输
> 
> HTTP/2不支持Transfer-Encoding: chunked，它有自己的**streaming传输方式**
> 


---

### HTTP状态码分类

* 1** 信息，服务器收到请求，需要请求者继续执行操作
* 2** 成功，操作被成功接收并处理
* 3** 重定向，需要进一步操作以完成请求
* 4** 客户端错误，请求包含语法错误或无法完成请求
* 5** 服务器错误，服务器在处理请求的过程中发生了错误

**常见的状态码**

| 状态码 | 名称 | 描述 |
| - | - | - |
| 100 | Continue | 客户端应继续请求 |
| 101 | Switching Protocols | 服务器根据客户端的请求切换至更高级的协议 |
| --- |
| 200 | OK | 请求成功 |
| 201 | Created | 成功请求并创建了资源 |
| 202 | Accept | 已接受请求，但未完成处理 |
| 205 | Reset Content | 服务器处理请求成功，客户端应重置内容 |
| --- |
| 300 | Multiple Choices | 请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301 | Moved Permenantly | 永久移动 |
| 302 | Found | 临时移动，客户端应继续使用当前url |
| 304 | Not Modified | 文档内容未改变 |
| 305 | Use Agent | 用户所访问的资源应该通过代理访问 |
| --- |
| 400 | Bad Request | 请求的语法错误，服务器无法理解 |
| 401 | Unauthorized | 请求需要身份认证 |
| 403 | Forbidden | 服务器理解请求，但拒绝处理请求 |
| 404 | Not Found | **服务器无法根据客户端的请求找到资源（网页）** |
| 405 | Method Not Allowed | 客户端请求的方法被终止 |
| --- |
| 500 | Internal Server Error | 服务器内部错误无法完成请求 |
| 501 | Not Implemented	| 服务器不支持请求的功能，无法完成请求 |
| 502 | Bad GateWay | 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 |
| 503 | Service Unavailable | 超载或者系统维护 |
| 504 | Gateway Time-out |	充当网关或代理的服务器，未及时从远端服务器获取请求|


## HTTP/2

**二级制协议**

HTTP/1.1头信息是ASCII编码的文本，而HTTP/2是二进制协议，头信息和数据体都是二进制，统称为帧（frame）。可以定义额外的帧，二进制解析更方便


**多工**

**双向，实时**的通信。客户端和浏览器都可以同时发送多个请求或者回应。服务器可以返回部分处理好的数据。

**数据流**

每个请求或者回应的所有数据包称为一个数据流。

数据流拥有唯一的id标识，客户端发出的为奇数，服务器发出的为偶数。数据包必须做**标记**以区分所属的数据流。

客户端和服务端可以发送RST_STREAM取消数据流，而不需要关闭TCP连接。

客户端可以指定数据流的优先级。

**头信息压缩**

HTTP协议是无状态的，每次请求都必须附上所有信息，导致字段的重复，浪费带宽。

* 头信息压缩机制: gzip/compress
* 客户端和服务端同时维护一直头信息表，使用索引号

**服务器推送**

HTTP/2允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。


## HTTP Pipelining

默认情况下，传输层连接只能承载一个请求和一个响应，浏览器会在收到上一个请求的响应之后再发送下一个请求。

HTTP管线化是将多个HTTP请求整批提交的技术，在传送过程中不需要等待服务器的响应。管线化机制是通过持久连接实现的。

* 只有GET和HEAD请求能进行管线化，POST有限制
* 初次建立连接时不进行管线化
* HTTP/1.1要求服务端也支持管线化，但对响应的返回是否管线化不做要求，仅需要服务器能处理管线化的请求。


## 会话跟踪

会话：客户端打开与服务端的连接发送请求给服务端到服务端响应请求的全过程称之为会话。

会话跟踪：同一个用户对服务器连续的跟踪和接受响应的监视。

为什么需要Sesstion Track？

原因：HTTP是无状态协议，无法保存用户的信息，服务端需要判断多个请求是否来源于同一个用户。

**常见的方式**

* URL重写：URL中增加会话id标识
* 隐藏表单域：将会话id添加到html元素提交到服务器，表单元素对用户隐藏
* Cookie：服务端发送给客户端的一小段信息。对用户的每次请求，服务端都会将Cookie发送到客户端保存，以便下次请求使用。客户端发送请求时可以读取Cookie发送到服务器端，以进行用户的识别
  + 临时Cookie：Cookie对象保存在内存中，浏览器关闭则该Cookie被清除
  + 永久Cookie：保存在磁盘中。有效期内都可以读取并发送到服务器
* Session：每个用户独享一个Session。服务端创建一个Session对象，放入到Cookie中返回给客户端。Session的实现依赖于Cookie，Cookie被禁用则Session也不能使用


## 跨站攻击

### CSRF（Cross-site request forgery, 跨站请求伪造）

伪造请求，冒充用户在站内的正常操作。

> **example**
> 
> 例如，一论坛网站的发贴是通过 GET 请求访问，点击发贴之后 JS 把发贴内容拼接成目标 URL 并访问：
> ```
> http://example.com/bbs/create_post.php?title=标题&content=内容
> ```
> 
> 那么，我们只需要在论坛中发一帖，包含一链接：
> ```
> http://example.com/bbs/create_post.php?title=我是脑残&content=哈哈
> ```
>
> 只要有用户点击了这个链接，那么他们的帐户就会在不知情的情况下发布了这一帖子。

CSRF攻击要成功的条件在于攻击者能够预测所有的参数从而构造出合法的请求。

**防范CSRF：**

* 关键操作采用POST
* 验证码
* 检测Referer：页面与页面之间的联系。
  + 问题在于服务端不总是能够接收Referer。所以一般用于监控CSRF的发生而不是抵御。
* Token：保持原有参数不变，添加一个随机不可预测的Token。
  + Token需要足够随机
  + 一次性，保持更新
  + 保密性，使用post


### XSS（Cross-site scripting, 跨站脚本攻击）

> XSS 全称“跨站脚本”，是注入攻击的一种。其特点是不对服务器端造成任何伤害，而是通过一些正常的站内交互途径，例如发布评论，提交含有 JavaScript 的内容文本。这时服务器端如果没有**过滤或转义**掉这些脚本，作为内容发布到了页面上，其他用户访问这个页面的时候就会运行这些脚本。

**防御方式：**

永不相信用户的输入。对用户的输入进行处理，仅允许输入合理的值，其他一概过滤。

* 不需要用户输入html：进行HTML escape，对特定字符(比如标签）进行转换encode

* 需要保留html：
  + 使用html解析库进行解析，获取其中的用户数据。
  + 根据html的标签以及属性，重建html元素树。
  + 重建时，所有的标签以及属性都只从白名单中获取。


